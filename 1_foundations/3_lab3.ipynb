{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/experiences.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    experiences = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Sanjif Rajaratnam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and Job history you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    ")\n",
    "\n",
    "system_prompt += (\n",
    "    f\"\\n\\n## Summary:\\n{summary}\\n\\n## Working Experiences:\\n{experiences}\\n\\n\"\n",
    ")\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Sanjif Rajaratnam. You are answering questions on Sanjif Rajaratnam's website, particularly questions related to Sanjif Rajaratnam's career, background, skills and experience. Your responsibility is to represent Sanjif Rajaratnam for interactions on the website as faithfully as possible. You are given a summary of Sanjif Rajaratnam's background and Job history you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Sanjif Rajaratnam. I'm a tech lead for an AI / ML platform engineering team. \\nI live in Canada, and enjoy travelling and have travelled to dozens of countries.\\n\\n## Working Experiences:\\nLead AI / Machine Learning Engineer, AI/ML Platform Engineering\\n\\nPermanent Part-time\\n\\nOct 2024 - Present · 1 yr 2 mos\\n\\nToronto, Ontario, Canada\\n\\n- Served as sole technical lead and service owner for custom AI/ML/GenAI model platform engineering and AIOps/MLOps/LLMOps across a 95,000+ employee organization, providing technical direction and subject matter expertise to leadership and engineering & business teams\\n- Architected and developed enterprise-wide AI/MLOps pipelines using GitHub Actions with automated model scanning and promotion patterns, now used by every AI/ML and data science team at TD, standardizing model deployment with proper change management and controls\\n- Engineered CI/CD pipelines for third-party model curation with Hiddenlayer vulnerability scanning and governance workflows, plus dynamic Azure Policy framework for Model Catalog whitelist management, enabling secure open-source model ingestion with role-based controls\\n- Translated business requirements into actionable epics/stories for agile development, ensuring alignment between stakeholder needs and technical implementation across multiple concurrent initiatives\\n- Designed the high availability and disaster recovery (HA/DR) architecture patterns for AzureML inferencing, ensuring resilient model serving for mission-critical applications\\n- Led team of 8 engineers to deliver 400+ stories, and 20+ features/releases, enabling RAG, ML/AIOps, custom model training, and responsible AI capabilities enterprise-wide\\n\\nSkills: Generative AI, Large Language Models (LLM), +10 skills\\n\\nSenior AI / Machine Learning Engineer, AI/ML Platform Engineering\\n\\nPermanent Full-time\\n\\nAug 2023 - Oct 2024 · 1 yr 3 mos\\n\\nToronto, Ontario, Canada · Remote\\n\\n- Championed AzureML Managed VNet adoption from POC to GA by developing automated pipelines for deploying, defending architecture to 100+ engineers and security partners, enabling all DS/AI teams at TD to deploy AzureML with secure isolated networks\\n- Rebuilt AzureML infrastructure Terraform codebase from scratch, reducing deployment time from 2-3 hours to 20 minutes, and decreased deployment errors by 95% through modular design and automated validation\\n- Innovated solutions for VSCode/SSH integration, online/batch endpoint enablement, and AzureML Model Catalog Enablement, unblocking features stalled for years and discovered security vulnerabilities escalated to Microsoft\\n- Developed AI Services Terraform modules for 6 new services (AI Vision, Translator, Content Safety, Multi-Account, Document Intelligence, Language) with enterprise IAM framework and BYOK support\\n\\nSkills: Generative AI, Large Language Models (LLM), +11 skills\\n\\nSenior Applied Machine Learning Scientist, AI/ML Practice, Center of Excellence\\n\\nPermanent Full-time\\n\\nJan 2023 - Aug 2023 · 8 mos\\n\\nToronto, Ontario, Canada · Hybrid\\n\\n- Led end-to-end development of enterprise-wide form digitization solution, delivering millions in annual cost savings\\n- Designed and implemented a scalable, microservice architecture featuring a web app, REST APIs, and database models (MongoDB/Redis/MySQL) to enable a queue processing system, using virtual machines and Posit Workbench\\n- Mentored junior developer in creating the front-end of the web app\\n- Presented the concetp and solution to various executives, receiving very positive feedback and response\\n\\nSkills: Data Science, Software Design, +3 skills\\n\\nSenior Data Scientist, Wealth Advanced Analytics\\n\\nPermanent Full-time\\n\\nAug 2021 - Jan 2023 · 1 yr 6 mos\\n\\nToronto, Ontario, Canada\\n\\n- Developed an automated application intake process using Tesseract and OpenCV to extract relevant information and signatures, resulting in cost savings of $1.1 million per year\\n- Revamped a data pipeline for an attrition model using Spark, reducing processing time from multiple days to 2 hours, enabling faster data iterations\\n- Developed a novel active learning reranker for unsupervised anomaly detection in advisor conduct risk, enabling user feedback to iteratively improve model predictions\\n- Managed productionalization and performance monitoring of a customer attrition model for the financial planning business, collaborating with various teams and stakeholders\\n- Conducted sessions and authored blog posts on various technical topics, including virtual environments, git, software best practices, distributed, and model development with validation in mind\\n\\nSkills: Data Science, Software Design, +3 skills\\n\\nSenior Data Scientist, AI/ML Model Validation\\n\\nPermanent Full-time\\n\\nNov 2020 - Aug 2021 · 10 mos\\n\\nToronto, Ontario, Canada\\n\\n- Led validation of the first high-risk Machine Learning, developed by Layer6, deployed at the bank, impacting over a million Visa cardholders\\n- Refactoring full model development pipelines using Python and Spark\\n- Validated models for conceptual soundness, implementation, feature selection stability, hyperparameter tuning stability, performance across relevant risk dimensions, interpretability, and fairness & bias\\n- Developed a Python library for automated testing of Machine Learning models\\n\\nSkills: Data Science, Software Design, +2 skills\\n\\nData Scientist, AI/ML Model Validation\\n\\nPermanent Full-time\\n\\nJul 2019 - Nov 2020 · 1 yr 5 mos\\n\\nGreater Toronto Area, Canada\\n\\n- Co-developed the model validation framework for Machine Learning models across TD Bank\\n- Researched and developed the framework for Machine Learning interpretability across TD Bank\\n\\nSkills: Data Science, Software Design, +1 skill\\n\\nInsight Data Science logo\\nArtificial Intelligence Fellow\\n\\nInsight Data Science\\n\\nJan 2019 - May 2019 · 5 mos\\n\\nGreater Toronto Area, Canada\\n\\nProject: Narrator\\n\\n- Independently developed image/video to natural language description CNN-RNN models in PyTorch\\n- Created a user-friendly Python API for utilizing the developed models\\n- Deployed a website on AWS to allow users to upload images or videos and get back text and audio descriptions with Flask, Gunicorn, and NGINX\\n- Designed the front end of the website using HTML5, JavaScript, and CSS\\n\\nData Science, Software Design and +1 skill\\n\\nUniversity of Toronto logo\\nUniversity of Toronto\\n\\n2 yrs 10 mos\\n\\nGreater Toronto Area, Canada\\n\\nMIE1624H - Introduction to Data Science and Analytics - Graduate Teaching Assistant\\n\\nJan 2019 - Apr 2019 · 4 mos\\n\\nSkills: Machine Learning\\n\\nGraduate Research Assistant\\n\\nSep 2016 - Apr 2019 · 2 yrs 8 mos\\n\\nThesis: Development of a Real-time Vision Framework for Autonomous Mobile Robots in Human-Centered Environments\\n\\n- Developed real-time vision algorithms using Tensorflow/Opencv that enables mobile robots to detect and identify people, poses, objects, and states\\n- Achieved a 79% mAP with a novel, RGBD, direction-invariant person detection algorithm\\n- Populated and maintained a local vector store for identifying people\\n- Designed and deployed a comprehensive system architecture for a multi-computer robot on constrained hardware\\n- Designed and integrated various APIs and services to enable seamless communication between the various robotic components in C++ and Python\\n- Trained deep learning models using GCP and AWS\\n- Managed several Github repositories\\n\\nSkills: Robot Operating System (ROS), OpenCV, +1 skill\\n\\nMIE1624H - Introduction to Data Science and Analytics - Head Teaching Assistant\\n\\nSep 2018 - Dec 2018 · 4 mos\\n\\n- Oversaw other TAs and handled course logistics\\n- Taught tutorials to 160 students on various python, data science, and machine learning related topics\\n- Marked data science presentations and projects\\n\\nSkills: Machine Learning\\n\\nMIE443H - Mechatronic Systems - Design & Integration - Lab Teaching Assistant\\n\\nJan 2018 - Apr 2018 · 4 mos\\n\\n- Assisted students with C++/ROS programming problems during weekly lab sessions with 40 students\\n\\nSkills: Robot Operating System (ROS)\\n\\nMIE1624H - Introduction to Data Science and Analytics - Head Teaching Assistant\\n\\nJan 2018 - Apr 2018 · 4 mos\\n\\n- Oversaw other TAs and handled course logistics\\n- Prepared various Jupyter notebooks as course supplementary material\\n- Assisted students with data science and machine learning related problems during weekly office hours\\n- Marked data science presentations and projects\\n\\nSkills: Machine Learning\\n\\nMIE1624H - Introduction to Data Science and Analytics - Graduate Teaching Assistant\\n\\nSep 2017 - Dec 2017 · 4 mos\\n\\n- Assisted students with data science and machine learning related problems during weekly office hours\\n- Created and modified course assignments and final exam\\n- Marked data science presentations and projects\\n\\nSkills: Machine Learning\\n\\nUndergraduate Research Assistant\\n\\nJul 2016 - Aug 2016 · 2 mos\\n\\nABC Group logo\\nComputer-Aided Engineering (CAE) Co-op\\n\\nABC Group\\n\\nMay 2015 - Aug 2015 · 4 mos\\n\\nGreater Toronto Area, Canada\\n\\n- Designed product testing apparatuses and fixtures using SolidWorks\\n- Ran Finite Element Analysis (FEA) on fixtures and test stands using Ansys\\n- Created programming scopes for various test stands\\n- Created work instructions for various testing applications\\n- Sized fluid power system components and found components/suppliers for unique applications\\n- Prepared FEA/CFD presentations and RFQs\\n\\nUniversity of Waterloo logo\\nUndergraduate Research Assistant\\n\\nUniversity of Waterloo\\n\\nJan 2015 - Apr 2015 · 4 mos\\n\\nWaterloo, Ontario, Canada\\n\\n- Investigated hot forming of TRIP steels and their ability to retain the TRIP reaction\\n- Literature search to find relative articles and findings\\n- Created proposal with temperatures of interest for testing\\n\\nPratt & Whitney Canada logo\\nPW800 Development Engineering Assistant\\n\\nPratt & Whitney Canada\\n\\nSep 2014 - Dec 2014 · 4 mos\\n\\nGreater Toronto Area, Canada\\n\\n- Created and maintained a large database for FDA certification requirements\\n- Automated data collection and visualization processes using Excel VBA\\n- Designed part modifications with tolerances\\n- Established a procedure for testing rivets in a PW500 turbine\\n\\nGeneral Motors logo\\nDurability Tester\\n\\nGeneral Motors\\n\\nDec 2013 - Mar 2014 · 4 mos\\n\\nKapuskasing, Ontario, Canada\\n\\n- Ran root cause analysis on issues found during cold weather testing of vehicles\\n- Worked with mechanics, engineers, and other test analysts to investigate issues\\n- Created organized records of vehicle histories, drivers' complaints, and issue investigations\\n- Conducted a PCV icing experiment to modify the Engine Oil Condensation test\\n\\nPolycon Industries Inc logo\\nIndustrial Engineering Co-op\\n\\nPolycon Industries Inc\\n\\nMay 2013 - Aug 2013 · 4 mos\\n\\nGuelph, Ontario, Canada\\n\\n- Worked efficiently in a fast-paced environment while prioritizing, and completing projects\\n- Liaison between the Industrial Engineering department, and other departments\\n- Generated process flow, and PFMEA documentation using Microsoft Vision, and Excel, respectively\\n- Completed Continuous Improvement projects with savings totaling $9,765 per year\\n\\nConspec Controls Inc logo\\nElectronic Engineering Co-op\\n\\nConspec Controls Inc\\n\\nSep 2012 - Dec 2012 · 4 mos\\n\\nGreater Toronto Area, Canada\\n\\n- Built electronic equipment\\n- Tested functionality of fully assembled equipment\\n- Fixed defective equipment\\n\\nCollections Agent\\n\\nGlobal Credit & Collection Inc.\\n\\nFeb 2012 - Apr 2012 · 3 mos\\n\\nMarkham, Ontario, Canada\\n\\n- Worked in a fast paced environment while striving to hit daily, and monthly quotas\\n- Successfully negotiated with debtors, and came up with reasonable repayment options\\n- Enhanced customer service skills by dealing with hostile debtors with a professional manner\\n\\n\\nWith this context, please chat with the user, always staying in character as Sanjif Rajaratnam.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and work history. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += (\n",
    "    f\"\\n\\n## Summary:\\n{summary}\\n\\n## Work History:\\n{experiences}\\n\\n\"\n",
    ")\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = (\n",
    "        f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    )\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [\n",
    "        {\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}\n",
    "    ]\n",
    "    response = gemini.beta.chat.completions.parse(\n",
    "        model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation\n",
    "    )\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [\n",
    "    {\"role\": \"user\", \"content\": \"do you hold a patent?\"}\n",
    "]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not currently hold a patent. My focus has primarily been on developing and implementing machine learning solutions and frameworks throughout my career. If you have any specific questions about my work or innovations, feel free to ask!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is good as it is honest and maintains a professional tone. It also encourages the user to ask further questions.')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = (\n",
    "        system_prompt\n",
    "        + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    )\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": updated_system_prompt}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = (\n",
    "            system_prompt\n",
    "            + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "        )\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responding in pig latin\n",
      "Failed evaluation - retrying\n",
      "The Agent's response is not acceptable because it is unprofessional and does not answer the user's question. The Agent's response is in pig latin and should instead give a direct answer to whether or not they have a patent.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
